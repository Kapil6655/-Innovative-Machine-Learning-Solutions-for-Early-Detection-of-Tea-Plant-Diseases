{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "K3qh47IVnzJp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gdNkp4-6cq3e"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import zipfile\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "drive.mount('/content/drive/MyDrive/tea leaf dataset')"
      ],
      "metadata": {
        "id": "Zx0zROClpqJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cqeIvqfqwKS",
        "outputId": "48e30f7e-75a8-44d0-ceff-df7ce8019d23"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_zip = '/content/drive/MyDrive/dataset.zip'  # Replace with your zip file location\n"
      ],
      "metadata": {
        "id": "Z8bQkZqNrE_1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from google.colab import drive\n",
        "import zipfile\n",
        "import os"
      ],
      "metadata": {
        "id": "elrCfJz6rxWW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPX7G2HKr0aq",
        "outputId": "e24fb771-7afa-417e-ac87-39ae9d62a39e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set dataset paths\n",
        "dataset_path = '/content/drive/MyDrive/tea leaf dataset'\n",
        "train_dir = os.path.join(dataset_path, 'train')\n",
        "validation_dir = os.path.join(dataset_path, 'validation')"
      ],
      "metadata": {
        "id": "MXU6KiUZr7HZ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model parameters\n",
        "IMG_HEIGHT, IMG_WIDTH = 224, 224  # Image dimensions\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 20\n",
        "LEARNING_RATE = 0.001"
      ],
      "metadata": {
        "id": "IMq9yYEosDCA"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Augmentation and Preprocessing\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255.0,\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")"
      ],
      "metadata": {
        "id": "wW_NsAnJsF4g"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_datagen = ImageDataGenerator(rescale=1.0 / 255.0)"
      ],
      "metadata": {
        "id": "nG8tXj3PsMMJ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "dataset_path = '/content/drive/MyDrive/tea leaf dataset'\n",
        "print(\"Contents of the dataset directory:\", os.listdir(dataset_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujr_KOKZszaG",
        "outputId": "a06c9bb0-e2a4-406b-dad2-a39bbbde9191"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of the dataset directory: ['healthy', 'bird eye spot', 'algal leaf', 'red leaf spot', 'gray light', 'brown blight', 'Anthracnose', 'white spot']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZCiYDsNs-wJ",
        "outputId": "dadcc159-9f7b-4963-a191-fdc5ba9d77f1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = '/content/drive/MyDrive/tea_leaf_dataset'\n",
        "train_dir = os.path.join(dataset_path, 'train')\n",
        "validation_dir = os.path.join(dataset_path, 'validation')\n"
      ],
      "metadata": {
        "id": "TCtG7oORtCnk"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set the base dataset path\n",
        "dataset_path = '/content/drive/MyDrive/tea leaf dataset'\n",
        "\n",
        "# List the contents of the base dataset path\n",
        "print(\"Contents of the dataset directory:\", os.listdir(dataset_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZfNifDstcct",
        "outputId": "a84fdd34-d781-4bd0-936f-3a59b0574783"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Contents of the dataset directory: ['healthy', 'bird eye spot', 'algal leaf', 'red leaf spot', 'gray light', 'brown blight', 'Anthracnose', 'white spot']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the contents of the 'tea leaf dataset' directory\n",
        "print(\"Contents of the 'tea leaf dataset':\", os.listdir(dataset_path))\n",
        "\n",
        "# Check if the 'train' and 'validation' folders exist\n",
        "train_dir = os.path.join(dataset_path, 'train')\n",
        "validation_dir = os.path.join(dataset_path, 'validation')\n",
        "\n",
        "print(\"Train directory exists:\", os.path.exists(train_dir))\n",
        "print(\"Validation directory exists:\", os.path.exists(validation_dir))\n",
        "\n",
        "# If train directory exists, list its contents\n",
        "if os.path.exists(train_dir):\n",
        "    print(\"Contents of the train directory:\", os.listdir(train_dir))\n",
        "\n",
        "# If validation directory exists, list its contents\n",
        "if os.path.exists(validation_dir):\n",
        "    print(\"Contents of the validation directory:\", os.listdir(validation_dir))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QgqQ2BOt0_n",
        "outputId": "9033c753-9031-4e04-dafc-e618b829a6e4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of the 'tea leaf dataset': ['healthy', 'bird eye spot', 'algal leaf', 'red leaf spot', 'gray light', 'brown blight', 'Anthracnose', 'white spot']\n",
            "Train directory exists: False\n",
            "Validation directory exists: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create directories if they don't exist\n",
        "if not os.path.exists(train_dir):\n",
        "    os.makedirs(train_dir)\n",
        "    print(\"Created train directory.\")\n",
        "\n",
        "if not os.path.exists(validation_dir):\n",
        "    os.makedirs(validation_dir)\n",
        "    print(\"Created validation directory.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajcouK-2t8yt",
        "outputId": "a9c176f7-20e3-495b-b239-0e3c088d91d6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created train directory.\n",
            "Created validation directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentation and preprocessing\n",
        "train_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
        "validation_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
        "\n",
        "# Load data from directories\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),  # Image dimensions\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k33mkAYzuP7g",
        "outputId": "965920f6-f126-456c-9b02-0b9d52ff80ae"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 images belonging to 0 classes.\n",
            "Found 0 images belonging to 0 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(train_generator.num_classes, activation='softmax')  # Output layer for each disease class\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35OZkn4lucO0",
        "outputId": "478f2430-336b-4f2b-c8af-4e15a9150f08"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=LEARNING_RATE),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "pmD2nmXGu3Yx"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Get the number of classes from the train generator\n",
        "num_classes = train_generator.num_classes\n",
        "\n",
        "# Example of a simple Convolutional Neural Network (CNN)\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(num_classes, activation='softmax')  # Make sure num_classes matches your dataset\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDOnZcVbwVo4",
        "outputId": "1c25642d-da2d-489f-ff4b-63487b7faf53"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a batch of training data\n",
        "x_batch, y_batch = next(train_generator)\n",
        "\n",
        "print(\"Batch shape:\", x_batch.shape)  # Should show (BATCH_SIZE, IMG_HEIGHT, IMG_WIDTH, 3)\n",
        "print(\"Labels shape:\", y_batch.shape)  # Should show (BATCH_SIZE, num_classes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlCpYkR6wYYr",
        "outputId": "a0e52ff5-ae9a-44ee-f0a0-9001845c3798"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch shape: (0, 224, 224, 3)\n",
            "Labels shape: (0, 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'  # For multiple classes\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uXsQCdewhSK",
        "outputId": "af626216-5ad5-4fa9-b74a-a149bd917cf8"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 images belonging to 0 classes.\n",
            "Found 0 images belonging to 0 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Get the number of classes from the train generator\n",
        "num_classes = train_generator.num_classes\n",
        "\n",
        "# Example of a simple Convolutional Neural Network (CNN)\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(num_classes, activation='softmax')  # Make sure num_classes matches your dataset\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',  # Use categorical_crossentropy for multi-class\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Ensure the input shape is correct\n",
        "# input_shape should match the shape of your images\n",
        "input_shape = (IMG_HEIGHT, IMG_WIDTH, 3)\n",
        "\n",
        "# Check the batch shape\n",
        "x_batch, y_batch = next(train_generator)\n",
        "\n",
        "# Check if the input shape matches the batch shape\n",
        "assert x_batch.shape[1:] == input_shape, f\"Input shape mismatch. Model expects {input_shape}, but got {x_batch.shape[1:]}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWac8Ip7wouO",
        "outputId": "2a9b85c0-39da-4650-d2ee-cf1bcc6b342d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "model.save('/content/drive/MyDrive/tea_leaf_disease_model.h5')\n",
        "print(\"Model training complete and saved to Google Drive.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vx0OYS7pvJ8z",
        "outputId": "63a5a6c8-bff5-4208-b20a-276b5d9c1b1f"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model training complete and saved to Google Drive.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}